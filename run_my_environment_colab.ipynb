{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tuxliri/RL_rocket/blob/test-PPO-gaudet-reward/run_my_environment_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bgoqZRSz3FQ"
      },
      "outputs": [],
      "source": [
        "!cat ~/.ssh/id_ed25519.pub\n",
        "PUB_KEY = \"ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIKRCMs6GPJ5kNi/fNVNf8Ki/QNwHS494mwuysriErNVs root@ac3a85e94cb7\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfW46krWzr4G"
      },
      "source": [
        "PRIVATE KEY:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4Uab7q5v8nS"
      },
      "outputs": [],
      "source": [
        "GITHUB_PRIVATE_KEY = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\n",
        "b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\n",
        "QyNTUxOQAAACCkQjLOhjyeZDYv3zVTX/Cov0DcB0uPeJsLsrK4hKzVbAAAAJhh7cU0Ye3F\n",
        "NAAAAAtzc2gtZWQyNTUxOQAAACCkQjLOhjyeZDYv3zVTX/Cov0DcB0uPeJsLsrK4hKzVbA\n",
        "AAAEDN2iiEa8wQ9vr1YZa/Db3A25rqlIJmgS5/JHXuCZNpeqRCMs6GPJ5kNi/fNVNf8Ki/\n",
        "QNwHS494mwuysriErNVsAAAAEXJvb3RAYWMzYTg1ZTk0Y2I3AQIDBA==\n",
        "-----END OPENSSH PRIVATE KEY-----\n",
        "\"\"\"\n",
        "\n",
        "# Create the directory if it doesn't exist.\n",
        "! mkdir -p /root/.ssh\n",
        "# Write the key\n",
        "with open(\"/root/.ssh/id_ed25519\", \"w\") as f:\n",
        "  f.write(GITHUB_PRIVATE_KEY)\n",
        "# Add github.com to our known hosts\n",
        "!ssh-keyscan -t ed25519 github.com >> ~/.ssh/known_hosts\n",
        "\n",
        "# Restrict the key permissions, or else SSH will complain.\n",
        "!chmod go-rwx /root/.ssh/id_ed25519\n",
        "\n",
        "# Note the `git@github.com` syntax, which will fetch over SSH instead of\n",
        "# HTTP.\n",
        "!git clone --branch test-PPO-gaudet-reward git@github.com:Tuxliri/RL_rocket.git\n",
        "\n",
        "!cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWzlYmiY141N"
      },
      "outputs": [],
      "source": [
        "!pip install stable-baselines3==1.5.0\n",
        "\n",
        "!pip install -e RL_rocket/.\n",
        "\n",
        "%cd RL_rocket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za9jCoewZZte"
      },
      "outputs": [],
      "source": [
        "% pip install wandb\n",
        "! pip install numpy==1.21.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiCJgT535o_N"
      },
      "source": [
        "**IMPORT ALL THE NEEDED PACKAGES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb-HCUk1v2KO"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from genericpath import exists\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import gym\n",
        "import wandb\n",
        "import numpy as np\n",
        "import stable_baselines3\n",
        "\n",
        "from stable_baselines3 import A2C, DQN, PPO, TD3\n",
        "from tensorboard import program\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.utils import set_random_seed\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from stable_baselines3.common.vec_env.dummy_vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.vec_env.vec_video_recorder import VecVideoRecorder\n",
        "\n",
        "import my_environment\n",
        "from my_environment.utils.callbacks import FigureRecorderCallback\n",
        "from my_environment.wrappers.wrappers import DiscreteActions3DOF\n",
        "from my_environment.envs import Rocket1D\n",
        "from gym.wrappers import TimeLimit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpwKGvd_v4sF"
      },
      "source": [
        "# Execute the training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZh-0qjN6l8B"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0whknuJU6tIm"
      },
      "source": [
        "**Environment definition**\n",
        "\n",
        "Here we define the environment, setting up the initial conditions, the range over which the initial conditions are generated and the timestep of the simulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MC0kpJp6Yuf"
      },
      "outputs": [],
      "source": [
        "# Choose the folder to store tensorboard logs\n",
        "TENSORBOARD_LOGS_DIR = \"./logs\"\n",
        "\n",
        "config = {\n",
        "        \"env_id\" : \"my_environment/Falcon3DOF-v0\",\n",
        "        \"policy_type\": \"MlpPolicy\",\n",
        "        \"total_timesteps\": int(3e6),\n",
        "        \"timestep\" : 0.05,\n",
        "        \"max_time\" : 40,\n",
        "        \"RANDOM_SEED\" : 42,\n",
        "        \"initial_conditions\" : [50, 500, np.pi/2, 0, -50, 0],\n",
        "        \"initial_conditions_range\" : [5,50,15*np.pi/180,0,0,0.01],\n",
        "        \"eval_freq\" : 50e3\n",
        "    }\n",
        "config[\"max_ep_timesteps\"] = int(config[\"max_time\"]/config[\"timestep\"])\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"RL_rocket\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "\n",
        "def make_env():\n",
        "    env = gym.make(\n",
        "    config[\"env_id\"],\n",
        "    IC=config[\"initial_conditions\"],\n",
        "    ICRange=config[\"initial_conditions_range\"],\n",
        "    timestep=config[\"timestep\"],\n",
        "    seed=config[\"RANDOM_SEED\"]\n",
        "    )\n",
        "    \n",
        "    # Define a new custom action space with only three actions:\n",
        "    # - no thrust\n",
        "    # - max thrust gimbaled right\n",
        "    # - max thrust gimbaled left\n",
        "    # - max thrust downwards\n",
        "\n",
        "    env = DiscreteActions3DOF(env)\n",
        "    env = TimeLimit(env, max_episode_steps=config[\"max_ep_timesteps\"])\n",
        "    env = Monitor(\n",
        "        env,\n",
        "        allow_early_resets=True,\n",
        "        filename=\"logs_PPO\",\n",
        "        )\n",
        "    return env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ1ZGrab6TJh"
      },
      "outputs": [],
      "source": [
        "env=make_env()\n",
        "model = PPO(\n",
        "    config[\"policy_type\"],\n",
        "    env,\n",
        "    tensorboard_log=f\"runs/{run.id}\",\n",
        "    verbose=1,\n",
        "    seed=config[\"RANDOM_SEED\"],\n",
        "    ent_coef=0.01,\n",
        "    )\n",
        "\n",
        "eval_env = VecVideoRecorder(model.get_env(), video_folder=f\"videos/{run.id}\",\n",
        "            record_video_trigger=lambda x : x == 0, video_length=config[\"max_ep_timesteps\"])\n",
        "            \n",
        "callbacksList = [\n",
        "    EvalCallback(\n",
        "        eval_env,\n",
        "        eval_freq = config[\"eval_freq\"],\n",
        "        n_eval_episodes = 5,\n",
        "        render=False,\n",
        "        deterministic=True,\n",
        "        # callback_after_eval=FigureRecorderCallback()\n",
        "        ),\n",
        "    WandbCallback(\n",
        "        model_save_path=f\"models/{run.id}\",\n",
        "        verbose=2,\n",
        "        gradient_save_freq=10000\n",
        "        )\n",
        "    ]\n",
        "\n",
        "model.learn(\n",
        "    total_timesteps=config[\"total_timesteps\"],\n",
        "    callback=callbacksList\n",
        ")\n",
        "\n",
        "run.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "run_my_environment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.12 ('beginnersPPO': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "6bb16cade9d36141ae9213d884fb1ae293e1d9fda2be68716a113c15fbf181a7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
