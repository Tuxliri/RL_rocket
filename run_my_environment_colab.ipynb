{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tuxliri/RL_rocket/blob/master/run_my_environment_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bgoqZRSz3FQ"
      },
      "outputs": [],
      "source": [
        "!cat ~/.ssh/id_ed25519.pub\n",
        "PUB_KEY = \"ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIKRCMs6GPJ5kNi/fNVNf8Ki/QNwHS494mwuysriErNVs root@ac3a85e94cb7\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfW46krWzr4G"
      },
      "source": [
        "PRIVATE KEY:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4Uab7q5v8nS"
      },
      "outputs": [],
      "source": [
        "GITHUB_PRIVATE_KEY = \"\"\"-----BEGIN OPENSSH PRIVATE KEY-----\n",
        "b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAMwAAAAtzc2gtZW\n",
        "QyNTUxOQAAACCkQjLOhjyeZDYv3zVTX/Cov0DcB0uPeJsLsrK4hKzVbAAAAJhh7cU0Ye3F\n",
        "NAAAAAtzc2gtZWQyNTUxOQAAACCkQjLOhjyeZDYv3zVTX/Cov0DcB0uPeJsLsrK4hKzVbA\n",
        "AAAEDN2iiEa8wQ9vr1YZa/Db3A25rqlIJmgS5/JHXuCZNpeqRCMs6GPJ5kNi/fNVNf8Ki/\n",
        "QNwHS494mwuysriErNVsAAAAEXJvb3RAYWMzYTg1ZTk0Y2I3AQIDBA==\n",
        "-----END OPENSSH PRIVATE KEY-----\n",
        "\"\"\"\n",
        "\n",
        "# Create the directory if it doesn't exist.\n",
        "! mkdir -p /root/.ssh\n",
        "# Write the key\n",
        "with open(\"/root/.ssh/id_ed25519\", \"w\") as f:\n",
        "  f.write(GITHUB_PRIVATE_KEY)\n",
        "# Add github.com to our known hosts\n",
        "!ssh-keyscan -t ed25519 github.com >> ~/.ssh/known_hosts\n",
        "\n",
        "# Restrict the key permissions, or else SSH will complain.\n",
        "!chmod go-rwx /root/.ssh/id_ed25519\n",
        "\n",
        "# Note the `git@github.com` syntax, which will fetch over SSH instead of\n",
        "# HTTP.\n",
        "!git clone --branch test-PPO-LL-rew git@github.com:Tuxliri/RL_rocket.git\n",
        "\n",
        "!cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWzlYmiY141N"
      },
      "outputs": [],
      "source": [
        "!pip install stable-baselines3==1.5.0\n",
        "\n",
        "!pip install -e RL_rocket/.\n",
        "\n",
        "%cd RL_rocket"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiCJgT535o_N"
      },
      "source": [
        "**IMPORT ALL THE NEEDED PACKAGES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb-HCUk1v2KO"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from genericpath import exists\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import gym\n",
        "import wandb\n",
        "import numpy as np\n",
        "import stable_baselines3\n",
        "\n",
        "from stable_baselines3 import A2C, DQN, PPO, TD3\n",
        "from tensorboard import program\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env.vec_normalize import VecNormalize\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.utils import set_random_seed\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from stable_baselines3.common.vec_env.dummy_vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.vec_env.vec_video_recorder import VecVideoRecorder\n",
        "\n",
        "import my_environment\n",
        "from my_environment.utils.callbacks import FigureRecorderCallback\n",
        "from my_environment.wrappers.wrappers import DiscreteActions, DiscreteActions3DOF\n",
        "from my_environment.envs import Rocket1D\n",
        "from gym.wrappers import FlattenObservation, FilterObservation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpwKGvd_v4sF"
      },
      "source": [
        "# Execute the training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZh-0qjN6l8B"
      },
      "source": [
        "Setup tensorboard dashboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0whknuJU6tIm"
      },
      "source": [
        "**Environment definition**\n",
        "\n",
        "Here we define the environment, setting up the initial conditions, the range over which the initial conditions are generated and the timestep of the simulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MC0kpJp6Yuf"
      },
      "outputs": [],
      "source": [
        "# Choose the folder to store tensorboard logs\n",
        "TENSORBOARD_LOGS_DIR = \"./logs\"\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "env_id = \"my_environment/Falcon3DOF-v0\"\n",
        "initial_conditions = [80, 500, np.pi/2, 0, -50, 0]\n",
        "initial_conditions_range = [0,50,0,0,10,0]\n",
        "timestep = 0.05\n",
        "\n",
        "\n",
        "config = {\n",
        "\"policy_type\": \"MlpPolicy\",\n",
        "\"total_timesteps\": int(1.5e6),\n",
        "}\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"sb3\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "def make_env():\n",
        "        env = gym.make(\n",
        "        env_id,\n",
        "        IC=initial_conditions,\n",
        "        ICRange=initial_conditions_range,\n",
        "        timestep=timestep,\n",
        "        seed=RANDOM_SEED\n",
        "        )\n",
        "        \n",
        "        # Define a new custom action space with only three actions:\n",
        "        # - no thrust\n",
        "        # - max thrust gimbaled right\n",
        "        # - max thrust gimbaled left\n",
        "        # - max thrust downwards\n",
        "        disc_to_cont = [\n",
        "            [0, -1], [-1, +1],\n",
        "            [0, +1], [+1, +1]\n",
        "                        ]\n",
        "    \n",
        "        env = DiscreteActions3DOF(env, disc_to_cont)\n",
        "        env = Monitor(\n",
        "            env,\n",
        "            allow_early_resets=True,\n",
        "            filename=\"logs_PPO\",\n",
        "            )\n",
        "        return env\n",
        "\n",
        "env = DummyVecEnv([make_env])\n",
        "env = VecVideoRecorder(env, video_folder=f\"videos/{run.id}\", record_video_trigger=lambda x : x % 10000 == 0, video_length=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ1ZGrab6TJh"
      },
      "outputs": [],
      "source": [
        "##\n",
        "model = PPO(\n",
        "    config[\"policy_type\"],\n",
        "    env,\n",
        "    tensorboard_log=TENSORBOARD_LOGS_DIR,\n",
        "    verbose=1,\n",
        "    seed=RANDOM_SEED\n",
        ")\n",
        "\n",
        "\n",
        "callbacksList = [\n",
        "    # EvalCallback(\n",
        "    #     model.get_env(),\n",
        "    #     eval_freq = 50e3,\n",
        "    #     n_eval_episodes=1,\n",
        "    #     # best_model_save_path=os.path.join(savefolder, filename),\n",
        "    #     render=False,\n",
        "    #     callback_after_eval=FigureRecorderCallback()\n",
        "    #     ),\n",
        "    WandbCallback(\n",
        "        model_save_path=f\"models/{run.id}\",\n",
        "        verbose=2,\n",
        "        gradient_save_freq=30000\n",
        "        )\n",
        "    ]\n",
        "\n",
        "model.learn(\n",
        "    total_timesteps=config[\"total_timesteps\"],\n",
        "    callback=callbacksList\n",
        ")\n",
        "\n",
        "rewards = evaluate_policy(model=model,env=model.get_env(),render=False,n_eval_episodes=10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "run_my_environment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.13 ('beginnersPPO': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "6bb16cade9d36141ae9213d884fb1ae293e1d9fda2be68716a113c15fbf181a7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}